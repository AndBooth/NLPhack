{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Investigate Paragram embeddings\n",
    "Looking into another word embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator \n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def threshold_search(y_true, y_proba):\n",
    "    best_threshold = 0\n",
    "    best_score = 0\n",
    "    for threshold in [i * 0.01 for i in range(51)]:\n",
    "        score = metrics.f1_score(y_true=y_true, y_pred=y_proba > threshold)\n",
    "        if score > best_score:\n",
    "            best_threshold = threshold\n",
    "            best_score = score\n",
    "    search_result = {'threshold': best_threshold, 'f1': best_score}\n",
    "    return search_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1306122, 3)\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv('../../data/train.csv')\n",
    "#test = pd.read_csv('../../data/test.csv')\n",
    "print(train.shape)\n",
    "#print(test.shape)\n",
    "train.fillna('_na_', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Embedding file using google news word2vec\n",
    "EMBEDDING_FILE = '../../data/embeddings/paragram_300_sl999/paragram_300_sl999.txt'\n",
    "def get_coefs(word,*arr): return word, np.asarray(arr, dtype='float32')\n",
    "embeddings_index = dict(get_coefs(*o.split(\" \")) for o in open(EMBEDDING_FILE, encoding=\"utf8\", errors='ignore') if len(o)>100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_DIM = len(embeddings_index['word'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_vocab(sentences, verbose =  True):\n",
    "    \"\"\"\n",
    "    :param sentences: list of list of words\n",
    "    :return: dictionary of words and their count\n",
    "    \"\"\"\n",
    "    vocab = {}\n",
    "    for sentence in tqdm(sentences, disable = (not verbose)):\n",
    "        for word in sentence:\n",
    "            try:\n",
    "                vocab[word] += 1\n",
    "            except KeyError:\n",
    "                vocab[word] = 1\n",
    "    return vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_coverage(vocab,embeddings_index):\n",
    "    a = {}\n",
    "    oov = {}\n",
    "    covered_word_count = 0\n",
    "    oov_word_count = 0\n",
    "    for word in tqdm(vocab):\n",
    "        try:\n",
    "            a[word] = embeddings_index[word]\n",
    "            covered_word_count += vocab[word]\n",
    "        except:\n",
    "\n",
    "            oov[word] = vocab[word]\n",
    "            oov_word_count += vocab[word]\n",
    "            pass\n",
    "\n",
    "    print('Found embeddings for {:.2%} of vocab'.format(len(a) / len(vocab)))\n",
    "    print('Found embeddings for  {:.2%} of all text'.format(covered_word_count / (covered_word_count + oov_word_count)))\n",
    "    sorted_x = sorted(oov.items(), key=operator.itemgetter(1))[::-1]\n",
    "\n",
    "    return sorted_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████| 1306122/1306122 [00:04<00:00, 324464.57it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████| 508823/508823 [00:00<00:00, 939993.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found embeddings for 19.59% of vocab\n",
      "Found embeddings for  72.21% of all text\n"
     ]
    }
   ],
   "source": [
    "sentences = list(map(lambda sent: sent.split(), train[\"question_text\"]))\n",
    "vocab = build_vocab(sentences) \n",
    "\n",
    "oov = check_coverage(vocab, embeddings_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('What', 417802),\n",
       " ('I', 306261),\n",
       " ('How', 261930),\n",
       " ('Why', 142291),\n",
       " ('Is', 108887),\n",
       " ('Can', 52698),\n",
       " ('Which', 47303),\n",
       " ('Do', 40041),\n",
       " ('If', 34557),\n",
       " ('Are', 29201),\n",
       " ('Does', 23180),\n",
       " ('Who', 21981),\n",
       " ('Where', 19146),\n",
       " ('Should', 16591),\n",
       " ('India?', 16384),\n",
       " ('Will', 14669),\n",
       " ('When', 14483),\n",
       " ('India', 13685),\n",
       " ('it?', 12900),\n",
       " ('Indian', 12895)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oov[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████| 1306122/1306122 [00:01<00:00, 956526.27it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████| 1306122/1306122 [00:03<00:00, 341519.76it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████| 450473/450473 [00:00<00:00, 971352.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found embeddings for 31.41% of vocab\n",
      "Found embeddings for  88.22% of all text\n"
     ]
    }
   ],
   "source": [
    "train[\"question_text\"] = train[\"question_text\"].progress_apply(lambda x: x.lower())\n",
    "\n",
    "sentences = list(map(lambda sent: sent.split(), train[\"question_text\"]))\n",
    "vocab = build_vocab(sentences) \n",
    "\n",
    "oov = check_coverage(vocab, embeddings_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('india?', 16394),\n",
       " (\"what's\", 13369),\n",
       " ('it?', 13158),\n",
       " ('do?', 8766),\n",
       " ('life?', 7791),\n",
       " ('why?', 7369),\n",
       " ('you?', 6314),\n",
       " ('me?', 6241),\n",
       " ('them?', 6141),\n",
       " ('time?', 5742),\n",
       " ('world?', 5525),\n",
       " ('people?', 5008),\n",
       " ('quora?', 4657),\n",
       " ('like?', 4490),\n",
       " ('for?', 4450),\n",
       " ('work?', 4219),\n",
       " ('2017?', 4050),\n",
       " ('mean?', 3980),\n",
       " ('2018?', 3594),\n",
       " (\"isn't\", 3509)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oov[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for symbol in '?!.,\"#$%\\'()*+-/:;<=>@[\\\\]^_`{|}~/-&“”’':\n",
    "#    print(symbol, symbol in embeddings_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def space_punct(x):\n",
    "    x = str(x)\n",
    "    for punct in '?!.,\"#$%\\'()*+-/:;<=>@[\\\\]^_`{|}~/-&“”’':\n",
    "        x = x.replace(punct, f' {punct} ')\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████| 1306122/1306122 [00:03<00:00, 341541.16it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████| 199047/199047 [00:00<00:00, 936839.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found embeddings for 73.15% of vocab\n",
      "Found embeddings for  99.62% of all text\n"
     ]
    }
   ],
   "source": [
    "train[\"question_text\"] = train[\"question_text\"].apply(lambda x: space_punct(x))\n",
    "sentences = train[\"question_text\"].apply(lambda x: x.split())\n",
    "vocab = build_vocab(sentences)\n",
    "\n",
    "oov = check_coverage(vocab, embeddings_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('quorans', 858),\n",
       " ('brexit', 524),\n",
       " ('cryptocurrencies', 499),\n",
       " ('redmi', 383),\n",
       " ('coinbase', 149),\n",
       " ('oneplus', 139),\n",
       " ('uceed', 123),\n",
       " ('demonetisation', 115),\n",
       " ('bhakts', 115),\n",
       " ('upwork', 111),\n",
       " ('machedo', 108),\n",
       " ('gdpr', 107),\n",
       " ('adityanath', 106),\n",
       " ('boruto', 102),\n",
       " ('bnbr', 100),\n",
       " ('alshamsi', 92),\n",
       " ('dceu', 90),\n",
       " ('litecoin', 87),\n",
       " ('iiest', 86),\n",
       " ('unacademy', 86)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oov[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
