{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Embeddings\n",
    "Word embedding binary can be found from the competition page along with the data https://www.kaggle.com/c/quora-insincere-questions-classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"]=\"3\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "from functools import partial\n",
    "from collections import defaultdict\n",
    "\n",
    "from gensim.models import KeyedVectors\n",
    "from nltk import word_tokenize\n",
    "from ecprocessing import text_preprocessing as txp\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def threshold_search(y_true, y_proba):\n",
    "    best_threshold = 0\n",
    "    best_score = 0\n",
    "    for threshold in [i * 0.01 for i in range(100)]:\n",
    "        score = metrics.f1_score(y_true=y_true, y_pred=y_proba > threshold)\n",
    "        if score > best_score:\n",
    "            best_threshold = threshold\n",
    "            best_score = score\n",
    "    search_result = {'threshold': best_threshold, 'f1': best_score}\n",
    "    return search_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import data and preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load in data\n",
    "train_df = pd.read_csv('../../data/train.csv')\n",
    "test_df = pd.read_csv('../../data/test.csv')\n",
    "\n",
    "X_train = train_df.question_text\n",
    "y_train = train_df.target\n",
    "\n",
    "X_test = test_df.question_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Preprocess\n",
    "normalize_text_lem = partial(txp.normalize_text, text_stemming='Lem')\n",
    "text_normalizer_lem = FunctionTransformer(lambda x: x.apply(normalize_text_lem), validate=False)\n",
    "text_normalizer_stem = FunctionTransformer(lambda x: x.apply(txp.normalize_text), validate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train_norm = text_normalizer_lem.fit_transform(X_train.fillna('NA'))\n",
    "#X_test_norm = text_normalizer_lem.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 8min 46s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_train_norm_s = text_normalizer_stem.fit_transform(X_train)\n",
    "#X_test_norm_s = text_normalizer_stem.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading word2vec embedding, easy to do with gensim KeyedVectors\n",
    "EMBEDDING_FILE = '../../data/embeddings/GoogleNews-vectors-negative300/GoogleNews-vectors-negative300.bin'\n",
    "wv = KeyedVectors.load_word2vec_format(EMBEDDING_FILE, binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmbeddingVectorizer(BaseEstimator, TransformerMixin):\n",
    "    '''Takes a word embedding and transforms documents into embedded vectors\n",
    "       by calculating embedding for each word and then combining\n",
    "       Can specify to use a weighted sum by fitting a Tfidf Vectorizer and using those weights'''\n",
    "    \n",
    "    def __init__(self, wv, weighted_vec=True, max_df=1., min_df=int(1)):\n",
    "        self.wv = wv\n",
    "        self.weighted_vec = weighted_vec\n",
    "        self.max_df = max_df\n",
    "        self.min_df = min_df\n",
    "        self.dim = wv.vector_size\n",
    "        \n",
    "    def fit(self, X):\n",
    "        if self.weighted_vec:\n",
    "            self.tfidf_vec = TfidfVectorizer(max_df=self.max_df, min_df=self.min_df)\n",
    "            self.tfidf_vec.fit(X)\n",
    "            # if a word was never seen - it must be at least as infrequent\n",
    "            # as any of the known words - so the default idf is the max of \n",
    "            # known idf's\n",
    "            \n",
    "            max_idf = max(self.tfidf_vec.idf_) \n",
    "            self.tfidf_dict = defaultdict(lambda: max_idf, zip(self.tfidf_vec.get_feature_names(), self.tfidf_vec.idf_))\n",
    "        return self\n",
    "        \n",
    "    def DocToWordVector(self, doc):\n",
    "        tokens = word_tokenize(doc)\n",
    "        vec = np.zeros(self.dim).reshape((1, self.dim))\n",
    "        count = 0.\n",
    "    \n",
    "        for word in tokens:\n",
    "            if self.weighted_vec:\n",
    "                weight = self.tfidf_dict[word]\n",
    "            else:\n",
    "                weight = 1\n",
    "            try:\n",
    "                vec += self.wv[word].reshape((1, self.dim)) * weight\n",
    "                count += 1.\n",
    "            except KeyError:      # handling the case where the token is not\n",
    "                                  # in the word embedding\n",
    "                continue\n",
    "    \n",
    "        if count != 0:\n",
    "            vec = vec / count\n",
    "        return vec\n",
    "            \n",
    "    def transform(self, X):\n",
    "        transformed_X = np.vstack(np.array(list(map(self.DocToWordVector, X))))\n",
    "        return transformed_X\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 4min 17s\n"
     ]
    }
   ],
   "source": [
    "# Can take a while to run\n",
    "%%time\n",
    "embed_transformer = EmbeddingVectorizer(wv, weighted_vec=True)\n",
    "X_train_wv = embed_transformer.fit_transform(X_train_norm_s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling\n",
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train test split\n",
    "X_train_mdl, X_test_mdl, y_train_mdl, y_test_mdl = train_test_split(X_train_wv, y_train, test_size=0.25, random_state=42, stratify=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tprjo\\AppData\\Local\\conda\\conda\\envs\\nlphack\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 55s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Train model\n",
    "clf = LogisticRegression()\n",
    "clf.fit(X_train_mdl, y_train_mdl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[303637   2691]\n",
      " [ 17763   2440]]\n",
      "0.19262650982868873\n"
     ]
    }
   ],
   "source": [
    "test_predictions = clf.predict(X_test_mdl)\n",
    "print(metrics.confusion_matrix(y_test_mdl, test_predictions))\n",
    "print(metrics.f1_score(y_test_mdl, test_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'threshold': 0.14, 'f1': 0.41263830103215265}\n"
     ]
    }
   ],
   "source": [
    "predictions_proba = clf.predict_proba(X_test_mdl)\n",
    "search_result = threshold_search(y_test_mdl, predictions_proba[:,1])\n",
    "print(search_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Doesn't perform very well, however we now have an input size of only 300 so we can turn to deep learning to increase performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
